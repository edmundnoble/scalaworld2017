To abstract over a collection of things, you satisfy yourself with a model, or concept, to avoid having to deal with the infinite differences between the things you describe with that model. You do this because you assume that the consumers of the abstraction, namely the questions you ask about that collection of things, will safely be able to ignore the differences between the things. It’s a shield you put between yourself and the thing-in-itself, as Kant would describe it; the code as it exists, not as you read it. And those can’t be the same thing, not just because your reading doesn’t always tell you how the program counter moves across the code (especially in higher-order applications) but also because your reading can’t tell you other things immediately like performance characteristics on a particular machine or whether or not you’re definitely maintaining your invariants. It’s something you do every day, come up with simple models to describe collections of things so that you have a more detailed structure of concepts with which to perceive the world and you don’t need to busy yourself with the uncountable differences between similar things.

Fundamentally there are two ways to create abstractions: from occurrences, or from concepts. Roughly this corresponds to whether you make an abstraction because you see a bunch of things and some kind of similar underlying nature makes itself apparent to you, or because you’ve been exposed to a concept in its textual, articulated form and have manipulated it into something new. And there’s no way to totally separate the two either, because you can only make an abstraction based on a bunch of things if you have the ability to perceive the things that make them similar, and often this means having a correct framework of concepts in which to place those things. There are a number of concepts and things which satisfy those concepts that you will not find without approaching the extremes of both these methods. There’s a reason why the Gang of Five book is so popular: teaching people patterns allows them to recognize them, and as the abstractions become larger and more complex it becomes more difficult (though not impossible) to come up with them from a representative set of examples. So the less we have to do of it, the faster we can get on with our *real* jobs.

An abstraction is leaky if the characteristics which describe whether something satisfies the abstraction do not enforce the full extent of the assumptions inherent in the abstraction’s use. A leaky abstraction is a heuristic, it’s a rule of thumb which hints at some deeper conceptual similarity but doesn’t have clean conceptual boundaries. The way you can tell if an abstraction is leaky is if the properties you assign to objects classified by that abstraction are all shared by the objects classified by that abstraction. In that sense, abstraction is an issue of your perception of the abstraction, not the abstraction itself; the abstraction is pure and real in a sense, and doesn’t have any connotations which aren’t part of its definition. You can’t interact with it directly, but you can come up with metaphors and examples which give a rough sketch of it in terms of what others already know, and then when you find counter-metaphors and counter-examples you need to amend your understanding of the abstraction. Therefore a leaky abstraction can be defined as an abstraction which you’ve got an incorrect or incomplete understanding of. I believe this to be one of the reasons why people have such large issues with what they call “over-analogizing” of functional programming concepts, because metaphors are harder to remove from your understanding of a concept when they’re incorrect or unusable than examples are, and at times it’s easy to sacrifice the concept entirely at the altar of your understanding of that concept, which guaranteed leads to a rough time spotting when it’s applicable and deriving things from it. This is also one reason to employ different, simultaneous methods of analysis to a concept: you can say that TCP is a leaky abstraction, because what it seems to promise in all circumstances is the removal of the unreliability of the network as a concern. But at another, more mechanistic level of analysis, TCP provides automatic message reordering and resending with certain characteristics with regard to wait times and buffering and so on, some of which can vary between implementations and all of which will vary between situations. These can be seen as equally correct, but differently useful and differently leaky depending on the problems you’re trying to solve by using TCP.

